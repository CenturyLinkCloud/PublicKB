{{{
  "title": "Getting Started with Apache Spark",
  "date": "07-28-2015",
  "author": "Kyle Mertz",
  "attachments": [],
  "contentIsHTML": false
}}}

## Overview

Apache Spark is available for install on a standalone CentOS or RHEL VM in CenturyLink Cloud.

<br>

**1. Navigate to the Blueprints Library and search for "spark".  Then choose the Apache Spark install Blueprint.**

![Apache Spark Blueprint](../images/Cloudera/Spark1.PNG)

<br>

**2. After clicking to deploy your Blueprint, select the VM that you'd like to install Apache Spark onto.**

![Apache Spark Server Selection](../images/Cloudera/Spark2.PNG)

<br>

**3. Review the details of your build and then click "deploy blueprint" at the bottom.**

![Apache Spark Deploy](../images/Cloudera/Spark3.PNG)

<br>

**4. Verify your build completed successfully.**

![Apache Spark Build](../images/Cloudera/Spark4.PNG)

<br>

### Details

After the build is complete, your SPARK_HOME will be located at:
>/usr/local/spark-1.4.1-bin-hadoop2.4

For more information on how to use Apache Spark, you can go [HERE](http://spark.apache.org/docs/latest/quick-start.html).
